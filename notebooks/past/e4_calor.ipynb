{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75dfb429",
   "metadata": {},
   "source": [
    "# Malha H3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15afbe",
   "metadata": {},
   "source": [
    "### 1. Exportar o H3 para .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715846ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. Lendo arquivo Parquet...\n",
      "2. Gerando coordenadas e colunas auxiliares...\n",
      "3. Salvando ../data/clean/h3/br/br_h3_cdmun_para_upload_gee.csv...\n",
      "Concluído! Pode fazer o upload no GEE.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "def preparar_csv_upload_com_setor():\n",
    "    path_input = '../data/clean/h3/br/br_h3_res9_com_setores.parquet'\n",
    "    # Mudei o nome levemente para você saber que é o novo\n",
    "    output_csv = '../data/clean/h3/br/br_h3_para_upload_gee.csv' \n",
    "\n",
    "    logging.info(\"1. Lendo arquivo Parquet...\")\n",
    "    df = pd.read_parquet(path_input)\n",
    "\n",
    "    logging.info(\"2. Gerando coordenadas e colunas auxiliares...\")\n",
    "    \n",
    "    # Gerar Lat/Lon (h3 ver. 4+)\n",
    "    coords = df['h3_id'].apply(h3.cell_to_latlng) \n",
    "    df['latitude'] = [x[0] for x in coords]\n",
    "    df['longitude'] = [x[1] for x in coords]\n",
    "\n",
    "    # Garantir que colunas de ID sejam strings (texto)\n",
    "    df['CD_MUN'] = df['CD_MUN'].astype(str)\n",
    "    df['CD_UF'] = df['CD_MUN'].str[:2]\n",
    "    \n",
    "    # --- NOVO: Garantir CD_SETOR ---\n",
    "    # Verifica se a coluna existe e converte para string\n",
    "    if 'CD_SETOR' in df.columns:\n",
    "        df['CD_SETOR'] = df['CD_SETOR'].astype(str)\n",
    "    else:\n",
    "        logging.warning(\"AVISO: Coluna 'CD_SETOR' não encontrada no arquivo!\")\n",
    "\n",
    "    # Selecionar colunas para exportação (Incluindo CD_SETOR agora)\n",
    "    cols_export = ['h3_id', 'latitude', 'longitude', 'CD_UF', 'CD_MUN', 'CD_SETOR']\n",
    "    \n",
    "    logging.info(f\"3. Salvando {output_csv}...\")\n",
    "    df[cols_export].to_csv(output_csv, index=False)\n",
    "    logging.info(\"Concluído! Pode fazer o upload no GEE.\")\n",
    "\n",
    "preparar_csv_upload_com_setor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe2322",
   "metadata": {},
   "source": [
    "### 2. Aplicar no Earth Engine Code Editor\n",
    "\n",
    "```javascript\n",
    "// --- 1. CONFIGURAÇÃO ---\n",
    "var table = ee.FeatureCollection(\"projects/ee2-linafaccin/assets/br_h3_cdmun_para_upload_gee\");\n",
    "\n",
    "// Lista de UFs\n",
    "var ufs = [\n",
    "  '11','12','13','14','15','16','17', \n",
    "  '21','22','23','24','25','26','27','28','29', \n",
    "  '31','32','33','35', \n",
    "  '41','42','43', \n",
    "  '50','51','52','53' \n",
    "];\n",
    "\n",
    "// --- 2. SATÉLITE COM REMOÇÃO DE NUVENS ---\n",
    "function prepL8(image) {\n",
    "  var qa = image.select('QA_PIXEL');\n",
    "  var mask = qa.bitwiseAnd(1 << 3).eq(0).and(qa.bitwiseAnd(1 << 4).eq(0));\n",
    "  return image.select('ST_B10')\n",
    "    .updateMask(mask)\n",
    "    .multiply(0.00341802).add(149.0).subtract(273.15)\n",
    "    .rename('temp_media_solo') // Renomeia a banda, mas o reducer precisa saber disso tb\n",
    "    .copyProperties(image, ['system:time_start']);\n",
    "}\n",
    "\n",
    "var landsat8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "    .filterDate('2014-01-01', '2024-12-31')\n",
    "    .map(prepL8);\n",
    "\n",
    "var lst_mean = landsat8.mean();\n",
    "\n",
    "// --- 3. PROCESSAMENTO E EXPORTAÇÃO ---\n",
    "ufs.forEach(function(uf_code) {\n",
    "  \n",
    "  var uf_collection = table.filter(ee.Filter.eq('CD_UF', uf_code));\n",
    "\n",
    "  var h3_with_temp = lst_mean.reduceRegions({\n",
    "    collection: uf_collection,\n",
    "    // --- CORREÇÃO: Forçar o nome da saída ---\n",
    "    reducer: ee.Reducer.mean().setOutputs(['temp_media_solo']), \n",
    "    scale: 30,\n",
    "    tileScale: 16\n",
    "  });\n",
    "\n",
    "  // Exporta\n",
    "  Export.table.toDrive({\n",
    "    collection: h3_with_temp,\n",
    "    description: 'H3_LST_UF_' + uf_code,\n",
    "    folder: 'GEE_Resultados_H3_Centroides',\n",
    "    fileFormat: 'CSV',\n",
    "    selectors: ['h3_id', 'CD_UF', 'CD_MUN', 'CD_SETOR', 'temp_media_solo']\n",
    "  });\n",
    "});\n",
    "\n",
    "print(\"Tarefas enviadas! Agora os nomes das colunas vão bater.\");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e8758",
   "metadata": {},
   "source": [
    "### 3. Juntar arquivos csv do GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3fcded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encontrados 27 arquivos. Iniciando leitura...\n",
      "Total carregado: 4892991 | Após remover duplicatas: 4892991\n",
      "Encontrados 265116 valores nulos. Tentando imputação...\n",
      "Temp Mínima: 3.99°C | Temp Máxima: 74.45°C\n",
      "SUCESSO! Arquivo salvo em: ../data/clean/h3/br/br_h3_res9_e4_calor.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "def finalizar_processamento_h3():\n",
    "    # Caminhos\n",
    "    path_csv_folder = '../data/raw/gee/land_surface_temperature/uf/' \n",
    "    path_output_parquet = '../data/clean/h3/br/br_h3_res9_e4_calor.parquet'\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path_csv_folder, \"*.csv\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        logging.error(\"Nenhum arquivo CSV encontrado!\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Encontrados {len(all_files)} arquivos. Iniciando leitura...\")\n",
    "\n",
    "    df_list = []\n",
    "    for filename in all_files:\n",
    "        # Lê garantindo que IDs sejam texto\n",
    "        df = pd.read_csv(filename, dtype={'CD_SETOR': str, 'CD_MUN': str, 'CD_UF': str})\n",
    "        df_list.append(df)\n",
    "\n",
    "    # 1. Consolidação\n",
    "    df_final = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # [MELHORIA 1] Remover duplicatas de H3_ID (segurança contra sobreposição de arquivos)\n",
    "    total_antes = len(df_final)\n",
    "    df_final = df_final.drop_duplicates(subset=['h3_id'])\n",
    "    logging.info(f\"Total carregado: {total_antes} | Após remover duplicatas: {len(df_final)}\")\n",
    "\n",
    "    # [MELHORIA 2] Limpar colunas desnecessárias do GEE\n",
    "    cols_drop = ['system:index', '.geo']\n",
    "    df_final = df_final.drop(columns=[c for c in df_final.columns if c in cols_drop])\n",
    "\n",
    "    # 2. Tratamento de Nulos (Estatística Local)\n",
    "    nulos = df_final['temp_media_solo'].isnull().sum()\n",
    "    if nulos > 0:\n",
    "        logging.warning(f\"Encontrados {nulos} valores nulos. Tentando imputação...\")\n",
    "        \n",
    "        # Tenta preencher com a média DO MUNICÍPIO primeiro (mais preciso)\n",
    "        df_final['temp_media_solo'] = df_final['temp_media_solo'].fillna(\n",
    "            df_final.groupby('CD_MUN')['temp_media_solo'].transform('mean')\n",
    "        )\n",
    "        \n",
    "        # Se ainda sobrar nulo (município inteiro sem dados), usa média geral\n",
    "        media_geral = df_final['temp_media_solo'].mean()\n",
    "        df_final['temp_media_solo'] = df_final['temp_media_solo'].fillna(media_geral)\n",
    "\n",
    "    # 3. Normalização (0 a 1)\n",
    "    # [DICA] Verificar se há outliers absurdos (ex: vulcão ou erro de sensor > 60 graus ou < -10)\n",
    "    # Aqui assumimos que a média de 10 anos suavizou isso.\n",
    "    t_min = df_final['temp_media_solo'].min()\n",
    "    t_max = df_final['temp_media_solo'].max()\n",
    "    logging.info(f\"Temp Mínima: {t_min:.2f}°C | Temp Máxima: {t_max:.2f}°C\")\n",
    "    \n",
    "    df_final['e4_cal_norm'] = (df_final['temp_media_solo'] - t_min) / (t_max - t_min)\n",
    "\n",
    "    # 4. Salvar\n",
    "    df_final.to_parquet(path_output_parquet, compression='snappy') # Snappy é rápido e padrão\n",
    "    logging.info(f\"SUCESSO! Arquivo salvo em: {path_output_parquet}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    finalizar_processamento_h3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e40dde",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa249151",
   "metadata": {},
   "source": [
    "# Setores Censitários"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c7350",
   "metadata": {},
   "source": [
    "### 1. Criar shp das UFs e converter para zip, para fazer upload no GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. Lendo arquivo de setores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2. Simplificando geometrias...\n",
      "3. Iniciando exportação por UF...\n",
      "   Processando UF 11...\n",
      "Created 3,456 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_11_gee.zip\n",
      "   Processando UF 12...\n",
      "Created 2,215 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_12_gee.zip\n",
      "   Processando UF 13...\n",
      "Created 11,755 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_13_gee.zip\n",
      "   Processando UF 14...\n",
      "Created 1,986 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_14_gee.zip\n",
      "   Processando UF 15...\n",
      "Created 18,635 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_15_gee.zip\n",
      "   Processando UF 16...\n",
      "Created 1,499 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_16_gee.zip\n",
      "   Processando UF 17...\n",
      "Created 4,119 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_17_gee.zip\n",
      "   Processando UF 21...\n",
      "Created 16,368 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_21_gee.zip\n",
      "   Processando UF 22...\n",
      "Created 7,340 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_22_gee.zip\n",
      "   Processando UF 23...\n",
      "Created 20,982 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_23_gee.zip\n",
      "   Processando UF 24...\n",
      "Created 6,096 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_24_gee.zip\n",
      "   Processando UF 25...\n",
      "Created 9,644 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_25_gee.zip\n",
      "   Processando UF 26...\n",
      "Created 19,700 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_26_gee.zip\n",
      "   Processando UF 27...\n",
      "Created 6,360 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_27_gee.zip\n",
      "   Processando UF 28...\n",
      "Created 5,347 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_28_gee.zip\n",
      "   Processando UF 29...\n",
      "Created 31,070 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_29_gee.zip\n",
      "   Processando UF 31...\n",
      "Created 51,392 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_31_gee.zip\n",
      "   Processando UF 32...\n",
      "Created 8,788 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_32_gee.zip\n",
      "   Processando UF 33...\n",
      "Created 42,270 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_33_gee.zip\n",
      "   Processando UF 35...\n",
      "Created 103,620 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_35_gee.zip\n",
      "   Processando UF 41...\n",
      "Created 23,899 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_41_gee.zip\n",
      "   Processando UF 42...\n",
      "Created 16,831 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_42_gee.zip\n",
      "   Processando UF 43...\n",
      "Created 25,575 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_43_gee.zip\n",
      "   Processando UF 50...\n",
      "Created 6,169 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_50_gee.zip\n",
      "   Processando UF 51...\n",
      "Created 9,385 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_51_gee.zip\n",
      "   Processando UF 52...\n",
      "Created 12,861 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_52_gee.zip\n",
      "   Processando UF 53...\n",
      "Created 5,418 records\n",
      "   -> Zip criado com sucesso: c:\\Users\\CarolinaFaccin\\OneDrive - World Resources Institute\\Carolina WRI\\Repositorios\\climate-justice-index\\data\\raw\\ibge\\setores_censitarios_cd2022\\gee_por_uf\\br_setores_cd2022_53_gee.zip\n",
      "Pronto! Todos os arquivos .zip foram gerados.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import logging\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Configuração de Logs\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "def preparar_setores_para_gee():\n",
    "    # Converta para caminho absoluto para evitar erros de \"../\"\n",
    "    input_path = os.path.abspath('../data/raw/ibge/setores_censitarios_cd2022/BR_setores_CD2022.gpkg')\n",
    "    output_dir = os.path.abspath('../data/raw/ibge/setores_censitarios_cd2022/gee_por_uf/')\n",
    "    \n",
    "    # Cria a pasta se ela não existir\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        logging.info(f\"Pasta criada: {output_dir}\")\n",
    "\n",
    "    logging.info(\"1. Lendo arquivo de setores...\")\n",
    "    gdf = gpd.read_file(input_path)\n",
    "    \n",
    "    logging.info(\"2. Simplificando geometrias...\")\n",
    "    gdf['geometry'] = gdf.geometry.simplify(tolerance=0.0001, preserve_topology=True)\n",
    "    \n",
    "    logging.info(\"3. Iniciando exportação por UF...\")\n",
    "    \n",
    "    gdf['CD_UF'] = gdf['CD_UF'].astype(str)\n",
    "    gdf_export = gdf[['CD_SETOR', 'CD_UF', 'CD_MUN', 'geometry']]\n",
    "    \n",
    "    ufs = gdf_export['CD_UF'].unique()\n",
    "    \n",
    "    for uf in ufs:\n",
    "        gdf_uf = gdf_export[gdf_export['CD_UF'] == uf]\n",
    "        \n",
    "        # Nome base do arquivo\n",
    "        base_name = f\"br_setores_cd2022_{uf}_gee\"\n",
    "        \n",
    "        # 1. Salvar como Shapefile NORMAL (não zipado ainda)\n",
    "        shp_path = os.path.join(output_dir, f\"{base_name}.shp\")\n",
    "        logging.info(f\"   Processando UF {uf}...\")\n",
    "        \n",
    "        try:\n",
    "            gdf_uf.to_file(shp_path, driver='ESRI Shapefile', encoding='utf-8')\n",
    "            \n",
    "            # 2. Zipar manualmente os arquivos gerados (.shp, .shx, .dbf, .prj, .cpg)\n",
    "            zip_path = os.path.join(output_dir, f\"{base_name}.zip\")\n",
    "            \n",
    "            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                # O Shapefile gera vários arquivos com o mesmo nome e extensões diferentes\n",
    "                extensions = ['.shp', '.shx', '.dbf', '.prj', '.cpg']\n",
    "                for ext in extensions:\n",
    "                    file_part = os.path.join(output_dir, base_name + ext)\n",
    "                    if os.path.exists(file_part):\n",
    "                        # Adiciona ao zip (arcname define o nome dentro do zip, sem pastas)\n",
    "                        zipf.write(file_part, arcname=base_name + ext)\n",
    "                        # Opcional: Apagar o arquivo solto depois de zipar\n",
    "                        os.remove(file_part)\n",
    "            \n",
    "            logging.info(f\"   -> Zip criado com sucesso: {zip_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"   Erro ao processar UF {uf}: {str(e)}\")\n",
    "\n",
    "    logging.info(\"Pronto! Todos os arquivos .zip foram gerados.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preparar_setores_para_gee()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773c4b1",
   "metadata": {},
   "source": [
    "### 2. Gerar a temperatura superficial média por setor censitário no Earth Engine Code Editor\n",
    "\n",
    "```javascript\n",
    "// --- 1. CONFIGURAÇÃO ---\n",
    "\n",
    "// Definimos a \"raiz\" do nome do seu asset\n",
    "var asset_base = \"projects/ee2-linafaccin/assets/br_setores_cd2022_\";\n",
    "var asset_suffix = \"_gee\";\n",
    "\n",
    "// Lista de UFs (Strings)\n",
    "var ufs = [\n",
    "  '11','12','13','14','15','16','17', // Norte\n",
    "  '21','22','23','24','25','26','27','28','29', // Nordeste\n",
    "  '31','32','33','35', // Sudeste\n",
    "  '41','42','43', // Sul\n",
    "  '50','51','52','53' // Centro-Oeste\n",
    "];\n",
    "\n",
    "// --- 2. PREPARAR SATÉLITE (Igual ao anterior) ---\n",
    "function prepL8(image) {\n",
    "  var qa = image.select('QA_PIXEL');\n",
    "  // Mascara nuvens e sombras (Bits 3 e 4)\n",
    "  var mask = qa.bitwiseAnd(1 << 3).eq(0).and(qa.bitwiseAnd(1 << 4).eq(0));\n",
    "  return image.select('ST_B10')\n",
    "    .updateMask(mask)\n",
    "    .multiply(0.00341802).add(149.0).subtract(273.15)\n",
    "    .rename('temp_media_solo')\n",
    "    .copyProperties(image, ['system:time_start']);\n",
    "}\n",
    "\n",
    "// Carrega a coleção Landsat 8 (2014-2024)\n",
    "var landsat8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "    .filterDate('2014-01-01', '2024-12-31')\n",
    "    .map(prepL8);\n",
    "\n",
    "// Calcula a média de todo o período em uma única imagem\n",
    "var lst_mean = landsat8.mean();\n",
    "\n",
    "// --- 3. PROCESSAMENTO (LOOP DINÂMICO) ---\n",
    "ufs.forEach(function(uf_code) {\n",
    "  \n",
    "  // AQUI ESTÁ A MUDANÇA: Construímos o ID do asset para esta UF específica\n",
    "  // Ex: projects/ee2-linafaccin/assets/br_setores_cd2022_24_gee\n",
    "  var asset_id = asset_base + uf_code + asset_suffix;\n",
    "  \n",
    "  // Carregamos apenas o estado da vez\n",
    "  var uf_collection = ee.FeatureCollection(asset_id);\n",
    "\n",
    "  // reduceRegions: Pega a média dos pixels dentro de cada polígono (Setor)\n",
    "  var setores_com_temp = lst_mean.reduceRegions({\n",
    "    collection: uf_collection,\n",
    "    reducer: ee.Reducer.mean().setOutputs(['temp_media_solo']), \n",
    "    scale: 30,\n",
    "    tileScale: 16 // Essencial para polígonos complexos não darem erro de memória\n",
    "  });\n",
    "\n",
    "  // Limpeza: Seleciona colunas e remove geometria para exportação leve\n",
    "  var export_collection = setores_com_temp.select(\n",
    "      ['CD_SETOR', 'CD_MUN', 'CD_UF', 'temp_media_solo'], \n",
    "      null, \n",
    "      false \n",
    "  );\n",
    "\n",
    "  // Exporta\n",
    "  Export.table.toDrive({\n",
    "    collection: export_collection,\n",
    "    description: 'Setores_LST_UF_' + uf_code,\n",
    "    folder: 'GEE_Setores_Temp_Final', // Sugiro uma pasta nova para não misturar com os hexágonos\n",
    "    fileFormat: 'CSV',\n",
    "    selectors: ['CD_SETOR', 'CD_MUN', 'CD_UF', 'temp_media_solo']\n",
    "  });\n",
    "});\n",
    "\n",
    "print(\"Tarefas enviadas! Verifique a aba Tasks.\");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b72c2",
   "metadata": {},
   "source": [
    "### 3. Unir os arquivos .csv e salvar em .gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e537d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. Buscando arquivos CSV de temperatura...\n",
      "   Encontrados 27 arquivos. Lendo...\n",
      "   Total de setores com temperatura recuperados: 468099\n",
      "2. Lendo arquivo GeoPackage de entrada: ../data/clean/sc/gpkg/BR_setores_CD2022_e1235_vul_int.gpkg\n",
      "3. Realizando o Join (GeoPackage + Dados de Temperatura)...\n",
      "   Encontrados 4024 setores sem dados de temperatura.\n",
      "   Realizando imputação pela média do município...\n",
      "   Nulos restantes após imputação: 0\n",
      "5. Calculando normalização 'e4_cal_norm'...\n",
      "   Temp Mínima: 11.25°C | Temp Máxima: 63.49°C\n",
      "6. Salvando arquivo GeoPackage: ../data/clean/sc/gpkg/BR_setores_CD2022_e12345_vul_int.gpkg\n",
      "Created 472,780 records\n",
      "7. Salvando arquivo CSV: ../data/clean/sc/csv/BR_setores_CD2022_e12345_vul_int.csv\n",
      "PROCESSO CONCLUÍDO COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Configuração de Logs\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "def processar_temperatura_setores():\n",
    "    # --- CAMINHOS ---\n",
    "    # Pasta onde estão os CSVs baixados do GEE\n",
    "    path_csv_folder = '../data/raw/gee/land_surface_temperature/sc_uf/'\n",
    "    \n",
    "    # Arquivo GPKG de entrada (O arquivo que já tem os índices e1, e2, e3, e5)\n",
    "    path_gpkg_input = '../data/clean/sc/gpkg/BR_setores_CD2022_e1235_vul_int.gpkg'\n",
    "    \n",
    "    # Arquivos de SAÍDA (GeoPackage e CSV)\n",
    "    path_gpkg_output = '../data/clean/sc/gpkg/BR_setores_CD2022_e12345_vul_int.gpkg'\n",
    "    path_csv_output  = '../data/clean/sc/csv/BR_setores_CD2022_e12345_vul_int.csv'\n",
    "\n",
    "    # Garante que as pastas de saída existem\n",
    "    os.makedirs(os.path.dirname(path_gpkg_output), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(path_csv_output), exist_ok=True)\n",
    "\n",
    "    # --- 1. LER E CONSOLIDAR OS CSVS DO GEE ---\n",
    "    logging.info(\"1. Buscando arquivos CSV de temperatura...\")\n",
    "    all_files = glob.glob(os.path.join(path_csv_folder, \"*.csv\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        logging.error(\"Nenhum CSV encontrado! Verifique o caminho.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"   Encontrados {len(all_files)} arquivos. Lendo...\")\n",
    "    \n",
    "    df_list = []\n",
    "    for filename in all_files:\n",
    "        # Importante: Ler CD_SETOR como string para não perder precisão ou zeros\n",
    "        df = pd.read_csv(filename, dtype={'CD_SETOR': str, 'CD_MUN': str, 'CD_UF': str})\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Junta todos os estados em um único DataFrame\n",
    "    df_temp = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Remove colunas inúteis do GEE se existirem\n",
    "    cols_drop = ['system:index', '.geo']\n",
    "    df_temp = df_temp.drop(columns=[c for c in df_temp.columns if c in cols_drop])\n",
    "    \n",
    "    # Remove duplicatas (prevenção)\n",
    "    df_temp = df_temp.drop_duplicates(subset=['CD_SETOR'])\n",
    "    \n",
    "    logging.info(f\"   Total de setores com temperatura recuperados: {len(df_temp)}\")\n",
    "\n",
    "    # --- 2. LER O GEOPACKAGE ORIGINAL ---\n",
    "    logging.info(f\"2. Lendo arquivo GeoPackage de entrada: {path_gpkg_input}\")\n",
    "    # Lê o arquivo que contém os dados anteriores\n",
    "    gdf_setores = gpd.read_file(path_gpkg_input)\n",
    "    \n",
    "    # Garantir que a chave de cruzamento seja string\n",
    "    gdf_setores['CD_SETOR'] = gdf_setores['CD_SETOR'].astype(str)\n",
    "\n",
    "    # --- 3. MERGE (CRUZAMENTO) ---\n",
    "    logging.info(\"3. Realizando o Join (GeoPackage + Dados de Temperatura)...\")\n",
    "    \n",
    "    # Selecionamos apenas as colunas de interesse do CSV\n",
    "    cols_to_merge = ['CD_SETOR', 'temp_media_solo']\n",
    "    \n",
    "    # Left Join: Mantém todos os setores do mapa\n",
    "    gdf_final = gdf_setores.merge(df_temp[cols_to_merge], on='CD_SETOR', how='left')\n",
    "\n",
    "    # --- 4. TRATAMENTO DE NULOS (IMPUTAÇÃO) ---\n",
    "    nulos = gdf_final['temp_media_solo'].isnull().sum()\n",
    "    if nulos > 0:\n",
    "        logging.warning(f\"   Encontrados {nulos} setores sem dados de temperatura.\")\n",
    "        logging.info(\"   Realizando imputação pela média do município...\")\n",
    "        \n",
    "        # Garante que temos CD_MUN\n",
    "        if 'CD_MUN' not in gdf_final.columns:\n",
    "            gdf_final['CD_MUN'] = gdf_final['CD_SETOR'].str[:7]\n",
    "\n",
    "        # 1. Média do MUNICÍPIO\n",
    "        gdf_final['temp_media_solo'] = gdf_final['temp_media_solo'].fillna(\n",
    "            gdf_final.groupby('CD_MUN')['temp_media_solo'].transform('mean')\n",
    "        )\n",
    "        \n",
    "        # 2. Fallback: Média GERAL\n",
    "        media_geral = gdf_final['temp_media_solo'].mean()\n",
    "        gdf_final['temp_media_solo'] = gdf_final['temp_media_solo'].fillna(media_geral)\n",
    "        \n",
    "        restantes = gdf_final['temp_media_solo'].isnull().sum()\n",
    "        logging.info(f\"   Nulos restantes após imputação: {restantes}\")\n",
    "\n",
    "    # --- 5. NORMALIZAÇÃO (0 a 1) ---\n",
    "    logging.info(\"5. Calculando normalização 'e4_cal_norm'...\")\n",
    "    \n",
    "    t_min = gdf_final['temp_media_solo'].min()\n",
    "    t_max = gdf_final['temp_media_solo'].max()\n",
    "    \n",
    "    logging.info(f\"   Temp Mínima: {t_min:.2f}°C | Temp Máxima: {t_max:.2f}°C\")\n",
    "    \n",
    "    # Fórmula Min-Max\n",
    "    gdf_final['e4_cal_norm'] = (gdf_final['temp_media_solo'] - t_min) / (t_max - t_min)\n",
    "\n",
    "    # --- 6. SALVAR ARQUIVOS ---\n",
    "    logging.info(f\"6. Salvando arquivo GeoPackage: {path_gpkg_output}\")\n",
    "    gdf_final.to_file(path_gpkg_output, driver='GPKG')\n",
    "    \n",
    "    logging.info(f\"7. Salvando arquivo CSV: {path_csv_output}\")\n",
    "    # Removemos a geometria para o CSV ficar leve e não dar erro de tamanho\n",
    "    df_csv = pd.DataFrame(gdf_final.drop(columns='geometry'))\n",
    "    df_csv.to_csv(path_csv_output, index=False)\n",
    "    \n",
    "    logging.info(\"PROCESSO CONCLUÍDO COM SUCESSO!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processar_temperatura_setores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
